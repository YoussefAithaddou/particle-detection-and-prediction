{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install keras==2.6.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "from ipywidgets import interact\n",
    "import tensorflow as tf\n",
    "\n",
    "from Training_Data.Particle_Tracking_Training_Data import Particle_Tracking_Training_Data\n",
    "\n",
    "from tensorflow.data import Dataset\n",
    "import keras\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Activation, Input, LeakyReLU, ConvLSTM2D, Conv2D\n",
    "import tensorflow.python.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nt = 20 ## number of frames for each video\n",
    "kappa = 0.1 ## standard deviation of background noise added to image \n",
    "a = 1. ## scale factor for the size of particle spots (not true size of particles) 3.0 make random(2.,8.)\n",
    "IbackLevel = 0.15 ## relative intensity of randomly generated background pattern; in (0, 1) \n",
    "Nparticles = 10 ## the number of particles (more => slower)\n",
    "sigma_motion = 3. ## the standard deviation for particle brownian motion; should be in (0, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(size, pt, kappa, a, IbackLevel, Nparticles, sigma_motion): \n",
    "    all_vid, all_labels, all_tracks = [],[],[]\n",
    "    for i in range(size): \n",
    "        vid, labels, tracks = pt(kappa, a, IbackLevel, Nparticles, sigma_motion) \n",
    "        all_vid.append(vid[:,::2,::2]) # downsample video to Ntx128x128\n",
    "        all_labels.append(labels)\n",
    "        all_tracks.append(tracks)\n",
    "    all_vid = tf.convert_to_tensor(all_vid) \n",
    "    all_labels = tf.convert_to_tensor(all_labels) \n",
    "    all_tracks = tf.convert_to_tensor(all_tracks)\n",
    "    \n",
    "    if Nt == 1:\n",
    "        all_vid = tf.transpose(all_vid, perm=[0,2,3,1])\n",
    "        #all_labels = tf.transpose(all_labels[:,:,:,:,1], perm=[0,2,3,1])\n",
    "    else:\n",
    "        all_vid = tf.expand_dims(all_vid, 4)\n",
    "        #all_labels = tf.expand_dims(all_labels[:,:,:,:,1], 4)\n",
    "    #print(all_labels.shape)\n",
    "    all_labels = tf.squeeze(all_labels)\n",
    "    #print(all_labels.shape)\n",
    "    return all_vid, all_labels, all_tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size1 = 200\n",
    "val_size1 = 50\n",
    "Nt = 1\n",
    "pt_single = Particle_Tracking_Training_Data(Nt) \n",
    "\n",
    "train_vid1, train_labels1, train_tracks1 = generate_data(train_size1, pt_single, kappa, a, IbackLevel, Nparticles, sigma_motion)\n",
    "val_vid1, val_labels1, val_tracks1 = generate_data(val_size1, pt_single, kappa, a, IbackLevel, Nparticles, sigma_motion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/51793737/custom-loss-function-for-u-net-in-keras-using-class-weights-class-weight-not\n",
    "\n",
    "def weightedLoss(originalLossFunc, weightsList):\n",
    "\n",
    "    def lossFunc(true, pred):\n",
    "        axis = -1 #if channels last \n",
    "        #axis=  1 #if channels first\n",
    "\n",
    "        #argmax returns the index of the element with the greatest value\n",
    "        #done in the class axis, it returns the class index    \n",
    "        classSelectors = K.argmax(true, axis=axis) \n",
    "            #if your loss is sparse, use only true as classSelectors\n",
    "\n",
    "        #considering weights are ordered by class, for each class\n",
    "        #true(1) if the class index is equal to the weight index  \n",
    "        classSelectors = tf.cast(classSelectors, tf.int32)\n",
    "        classSelectors = [K.equal(i, classSelectors) for i in range(len(weightsList))]\n",
    "\n",
    "        #casting boolean to float for calculations  \n",
    "        #each tensor in the list contains 1 where ground true class is equal to its index \n",
    "        #if you sum all these, you will get a tensor full of ones. \n",
    "        classSelectors = [K.cast(x, K.floatx()) for x in classSelectors]\n",
    "\n",
    "        #for each of the selections above, multiply their respective weight\n",
    "        weights = [sel * w for sel,w in zip(classSelectors, weightsList)] \n",
    "\n",
    "        #sums all the selections\n",
    "        #result is a tensor with the respective weight for each element in predictions\n",
    "        weightMultiplier = weights[0]\n",
    "        for i in range(1, len(weights)):\n",
    "            weightMultiplier = weightMultiplier + weights[i]\n",
    "\n",
    "\n",
    "        #make sure your originalLossFunc only collapses the class axis\n",
    "        #you need the other axes intact to multiply the weights tensor\n",
    "        loss = originalLossFunc(true,pred) \n",
    "        loss = loss * weightMultiplier\n",
    "\n",
    "        return loss\n",
    "    return lossFunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_f = tf.keras.metrics.Precision(class_id=1)\n",
    "recall_f = tf.keras.metrics.Recall(class_id=1)\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    precision = precision_f(y_true, y_pred)\n",
    "    recall = recall_f(y_true, y_pred)\n",
    "    f1_val = 2*(precision*recall)/(precision+recall)\n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "20/20 [==============================] - 8s 272ms/step - loss: 24.6145 - accuracy: 0.9062 - precision_1: 0.0019 - recall_1: 0.0460 - f1_score: 0.0038 - val_loss: 16.3132 - val_accuracy: 0.9961 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00 - val_f1_score: 0.0036\n",
      "Epoch 2/20\n",
      "20/20 [==============================] - 5s 261ms/step - loss: 8.4046 - accuracy: 0.9591 - precision_1: 0.0137 - recall_1: 0.1415 - f1_score: 0.0056 - val_loss: 2.8641 - val_accuracy: 0.9843 - val_precision_1: 0.0500 - val_recall_1: 0.1757 - val_f1_score: 0.0118\n",
      "Epoch 3/20\n",
      "20/20 [==============================] - 5s 253ms/step - loss: 1.7848 - accuracy: 0.9726 - precision_1: 0.0588 - recall_1: 0.4264 - f1_score: 0.0199 - val_loss: 1.1810 - val_accuracy: 0.9756 - val_precision_1: 0.0808 - val_recall_1: 0.5271 - val_f1_score: 0.0320\n",
      "Epoch 4/20\n",
      "20/20 [==============================] - 5s 264ms/step - loss: 0.9151 - accuracy: 0.9782 - precision_1: 0.0978 - recall_1: 0.5916 - f1_score: 0.0421 - val_loss: 0.7640 - val_accuracy: 0.9800 - val_precision_1: 0.1097 - val_recall_1: 0.6071 - val_f1_score: 0.0533\n",
      "Epoch 5/20\n",
      "20/20 [==============================] - 6s 278ms/step - loss: 0.6222 - accuracy: 0.9828 - precision_1: 0.1332 - recall_1: 0.6619 - f1_score: 0.0622 - val_loss: 0.5608 - val_accuracy: 0.9815 - val_precision_1: 0.1308 - val_recall_1: 0.6914 - val_f1_score: 0.0729\n",
      "Epoch 6/20\n",
      "20/20 [==============================] - 5s 270ms/step - loss: 0.4950 - accuracy: 0.9847 - precision_1: 0.1555 - recall_1: 0.7034 - f1_score: 0.0814 - val_loss: 0.4708 - val_accuracy: 0.9878 - val_precision_1: 0.1903 - val_recall_1: 0.6898 - val_f1_score: 0.0907\n",
      "Epoch 7/20\n",
      "20/20 [==============================] - 5s 261ms/step - loss: 0.4098 - accuracy: 0.9875 - precision_1: 0.1904 - recall_1: 0.7254 - f1_score: 0.0984 - val_loss: 0.4099 - val_accuracy: 0.9855 - val_precision_1: 0.1694 - val_recall_1: 0.7323 - val_f1_score: 0.1071\n",
      "Epoch 8/20\n",
      "20/20 [==============================] - 5s 272ms/step - loss: 0.3591 - accuracy: 0.9879 - precision_1: 0.1987 - recall_1: 0.7442 - f1_score: 0.1138 - val_loss: 0.3734 - val_accuracy: 0.9895 - val_precision_1: 0.2227 - val_recall_1: 0.7135 - val_f1_score: 0.1218\n",
      "Epoch 9/20\n",
      "20/20 [==============================] - 5s 256ms/step - loss: 0.3227 - accuracy: 0.9886 - precision_1: 0.2106 - recall_1: 0.7536 - f1_score: 0.1281 - val_loss: 0.3387 - val_accuracy: 0.9889 - val_precision_1: 0.2148 - val_recall_1: 0.7355 - val_f1_score: 0.1352\n",
      "Epoch 10/20\n",
      "20/20 [==============================] - 5s 251ms/step - loss: 0.3018 - accuracy: 0.9890 - precision_1: 0.2171 - recall_1: 0.7587 - f1_score: 0.1408 - val_loss: 0.3118 - val_accuracy: 0.9869 - val_precision_1: 0.1912 - val_recall_1: 0.7708 - val_f1_score: 0.1471\n",
      "Epoch 11/20\n",
      "20/20 [==============================] - 5s 262ms/step - loss: 0.2734 - accuracy: 0.9895 - precision_1: 0.2295 - recall_1: 0.7750 - f1_score: 0.1524 - val_loss: 0.2891 - val_accuracy: 0.9895 - val_precision_1: 0.2305 - val_recall_1: 0.7598 - val_f1_score: 0.1584\n",
      "Epoch 12/20\n",
      "20/20 [==============================] - 5s 259ms/step - loss: 0.2618 - accuracy: 0.9893 - precision_1: 0.2260 - recall_1: 0.7753 - f1_score: 0.1632 - val_loss: 0.2748 - val_accuracy: 0.9864 - val_precision_1: 0.1887 - val_recall_1: 0.7951 - val_f1_score: 0.1683\n",
      "Epoch 13/20\n",
      "20/20 [==============================] - 5s 248ms/step - loss: 0.2427 - accuracy: 0.9899 - precision_1: 0.2384 - recall_1: 0.7876 - f1_score: 0.1728 - val_loss: 0.2635 - val_accuracy: 0.9927 - val_precision_1: 0.3062 - val_recall_1: 0.7404 - val_f1_score: 0.1780\n",
      "Epoch 14/20\n",
      "20/20 [==============================] - 5s 264ms/step - loss: 0.2441 - accuracy: 0.9897 - precision_1: 0.2329 - recall_1: 0.7765 - f1_score: 0.1820 - val_loss: 0.2833 - val_accuracy: 0.9952 - val_precision_1: 0.4163 - val_recall_1: 0.6934 - val_f1_score: 0.1867\n",
      "Epoch 15/20\n",
      "20/20 [==============================] - 5s 260ms/step - loss: 0.2232 - accuracy: 0.9898 - precision_1: 0.2375 - recall_1: 0.7894 - f1_score: 0.1905 - val_loss: 0.2286 - val_accuracy: 0.9909 - val_precision_1: 0.2620 - val_recall_1: 0.7789 - val_f1_score: 0.1948\n",
      "Epoch 16/20\n",
      "20/20 [==============================] - 5s 248ms/step - loss: 0.2143 - accuracy: 0.9906 - precision_1: 0.2533 - recall_1: 0.7818 - f1_score: 0.1985 - val_loss: 0.2258 - val_accuracy: 0.9851 - val_precision_1: 0.1785 - val_recall_1: 0.8230 - val_f1_score: 0.2020\n",
      "Epoch 17/20\n",
      "20/20 [==============================] - 5s 265ms/step - loss: 0.1924 - accuracy: 0.9911 - precision_1: 0.2650 - recall_1: 0.7953 - f1_score: 0.2054 - val_loss: 0.2261 - val_accuracy: 0.9946 - val_precision_1: 0.3864 - val_recall_1: 0.7313 - val_f1_score: 0.2096\n",
      "Epoch 18/20\n",
      "20/20 [==============================] - 5s 260ms/step - loss: 0.1878 - accuracy: 0.9914 - precision_1: 0.2714 - recall_1: 0.7894 - f1_score: 0.2129 - val_loss: 0.1965 - val_accuracy: 0.9921 - val_precision_1: 0.2938 - val_recall_1: 0.7750 - val_f1_score: 0.2166\n",
      "Epoch 19/20\n",
      "20/20 [==============================] - 5s 250ms/step - loss: 0.1724 - accuracy: 0.9911 - precision_1: 0.2655 - recall_1: 0.7986 - f1_score: 0.2196 - val_loss: 0.1897 - val_accuracy: 0.9931 - val_precision_1: 0.3239 - val_recall_1: 0.7718 - val_f1_score: 0.2232\n",
      "Epoch 20/20\n",
      "20/20 [==============================] - 5s 261ms/step - loss: 0.1623 - accuracy: 0.9915 - precision_1: 0.2762 - recall_1: 0.8037 - f1_score: 0.2260 - val_loss: 0.1798 - val_accuracy: 0.9928 - val_precision_1: 0.3149 - val_recall_1: 0.7770 - val_f1_score: 0.2296\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1adbbdd0b08>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 10\n",
    "epochs = 20\n",
    "\n",
    "model1 = Sequential()\n",
    "model1.add(Input((128,128,1)))\n",
    "model1.add(Conv2D(12, 3, padding='same', activation=LeakyReLU(alpha=0.01), strides=(1,1)))\n",
    "model1.add(Conv2D(32, 3, padding='same', activation=LeakyReLU(alpha=0.01), strides=(1,1)))\n",
    "model1.add(Conv2D(2, 3, padding='same', strides=(1,1)))\n",
    "model1.add(Activation('softmax'))\n",
    "\n",
    "model1.compile(optimizer='adam',\n",
    "             loss=weightedLoss(keras.losses.categorical_crossentropy, [0.1, 0.9]),\n",
    "             metrics=['accuracy', tf.keras.metrics.Precision(name='precision_1', class_id=1), \n",
    "                      tf.keras.metrics.Recall(name='recall_1', class_id=1), f1_score])\n",
    "\n",
    "num_batches = int(train_size1/batch_size)\n",
    "model1.fit(train_vid1, train_labels1, steps_per_epoch=num_batches, epochs=epochs, verbose=1, \n",
    "          validation_data=(val_vid1, val_labels1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 128, 128, 12)      120       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 128, 128, 32)      3488      \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 128, 128, 2)       578       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 128, 128, 2)       0         \n",
      "=================================================================\n",
      "Total params: 4,186\n",
      "Trainable params: 4,186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConvLSTM2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Generation (videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 10\n",
    "val_size = 3\n",
    "Nt = 10\n",
    "pt_video = Particle_Tracking_Training_Data(Nt)\n",
    "\n",
    "train_vid2, train_labels2, train_tracks2 = generate_data(train_size, pt_video, kappa, a, IbackLevel, Nparticles, sigma_motion)\n",
    "val_vid2, val_labels2, val_tracks2 = generate_data(val_size, pt_video, kappa, a, IbackLevel, Nparticles, sigma_motion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "5/5 [==============================] - 22s 4s/step - loss: 0.0054 - accuracy: 0.4862 - precision_1: 0.0038 - recall_1: 0.9791 - f1_score: 0.1556 - val_loss: 0.0052 - val_accuracy: 0.9394 - val_precision_1: 0.0036 - val_recall_1: 0.9938 - val_f1_score: 0.1089\n",
      "Epoch 2/5\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.0053 - accuracy: 0.7410 - precision_1: 0.0039 - recall_1: 0.9984 - f1_score: 0.0892 - val_loss: 0.0051 - val_accuracy: 0.3547 - val_precision_1: 0.0036 - val_recall_1: 0.9994 - val_f1_score: 0.0730\n",
      "Epoch 3/5\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.0053 - accuracy: 0.5090 - precision_1: 0.0039 - recall_1: 0.9998 - f1_score: 0.0641 - val_loss: 0.0051 - val_accuracy: 0.8030 - val_precision_1: 0.0036 - val_recall_1: 1.0000 - val_f1_score: 0.0559\n",
      "Epoch 4/5\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.0052 - accuracy: 0.7532 - precision_1: 0.0039 - recall_1: 0.9998 - f1_score: 0.0508 - val_loss: 0.0051 - val_accuracy: 0.4262 - val_precision_1: 0.0036 - val_recall_1: 1.0000 - val_f1_score: 0.0459\n",
      "Epoch 5/5\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.0052 - accuracy: 0.5392 - precision_1: 0.0039 - recall_1: 1.0000 - f1_score: 0.0426 - val_loss: 0.0050 - val_accuracy: 0.7444 - val_precision_1: 0.0036 - val_recall_1: 1.0000 - val_f1_score: 0.0393\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1adbc365e88>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 2\n",
    "epochs = 5\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Input((Nt,128,128,1)))\n",
    "model2.add(ConvLSTM2D(12, kernel_size=(3, 3), padding='same', strides=(1,1), \n",
    "                     return_sequences=True,  data_format='channels_last'))\n",
    "model2.add(ConvLSTM2D(16, kernel_size=(3, 3), padding='same', strides=(1,1), \n",
    "                     return_sequences=True,  data_format='channels_last'))\n",
    "model2.add(ConvLSTM2D(2, kernel_size=(3, 3), padding='same', strides=(1,1), \n",
    "                     return_sequences=True,  data_format='channels_last'))\n",
    "model2.add(Activation('sigmoid'))\n",
    "\n",
    "model2.compile(optimizer='adam',\n",
    "            loss=weightedLoss(keras.losses.categorical_crossentropy, [0.0039, 0.9961]),\n",
    "            metrics=['accuracy', tf.keras.metrics.Precision(name='precision_1', class_id=1), \n",
    "                      tf.keras.metrics.Recall(name='recall_1', class_id=1), f1_score])\n",
    "\n",
    "num_batches = int(train_size/batch_size)\n",
    "model2.fit(train_vid2, train_labels2, steps_per_epoch=num_batches, epochs=epochs, verbose=1, \n",
    "          validation_data=(val_vid2, val_labels2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=6313>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.reduce_sum(train_labels2[:,:,:,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9960980224609375"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-6393/(10*10*128*128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_lst_m2d (ConvLSTM2D)    (None, 10, 128, 128, 12)  5664      \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_1 (ConvLSTM2D)  (None, 10, 128, 128, 16)  16192     \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_2 (ConvLSTM2D)  (None, 10, 128, 128, 2)   1304      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10, 128, 128, 2)   0         \n",
      "=================================================================\n",
      "Total params: 23,160\n",
      "Trainable params: 23,160\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
